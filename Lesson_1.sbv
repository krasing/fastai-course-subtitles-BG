0:00:00.325,0:00:03.285
Здравейте и добре дошли в курса

0:00:03.285,0:00:06.305
"Многослойно машинно самообучение за програмисти", урок първи

0:00:06.305,0:00:07.505
Това е четвъртата

0:00:09.505,0:00:12.105
година, която го провеждаме,

0:00:12.560,0:00:15.720
но ще е много различна и много специална версия

0:00:16.220,0:00:18.960
поради ред причини

0:00:18.960,0:00:22.120
Първата причина да е различен, е че го провеждаме наживо

0:00:22.120,0:00:24.700
още от първия ден

0:00:24.700,0:00:28.500
на пълно или почти пълно затваряне на Сан Франциско

0:00:29.340,0:00:31.720
Ще го записваме през следващите два месеца

0:00:31.720,0:00:34.340
в разгарата на тази глобална пандемия

0:00:34.580,0:00:37.880
Затова, ако нещата изглеждат малко откачени от време навреме

0:00:37.880,0:00:41.700
моля да ме извините, това е причината

0:00:42.500,0:00:47.460
Друга причина, да е специален,

0:00:49.220,0:00:53.440
е че опитваме да го направим един вид окончателна версия.

0:00:53.980,0:00:57.000
След като го провеждаме от край време,

0:00:57.000,0:00:59.340
най-накрая стигнахме до точка, в която

0:00:59.340,0:01:01.320
като че ли знаем за какво говорим.

0:01:01.600,0:01:05.500
До ниво в което Силвен и аз написахме истинска книга

0:01:05.900,0:01:08.775
и действащ софтуер

0:01:08.780,0:01:11.785
от нулата, наречен библиотека fastai, версия 2,

0:01:11.785,0:01:15.720
написахме рецензирана статия

0:01:16.120,0:01:18.120
за тази библиотека

0:01:18.380,0:01:21.760
така че това е замислено да е версията на курса,

0:01:22.080,0:01:26.200
която надяваме се ще остане.

0:01:27.340,0:01:30.040
Учебната програма следва доста точно съдържанието

0:01:30.160,0:01:33.800
на книгата, така че ако искате да

0:01:34.060,0:01:36.260
четете едновременно с провеждане на курса,

0:01:36.460,0:01:38.455
моля купете я.

0:01:38.460,0:01:40.880
Казвам моля купете я, защото

0:01:41.120,0:01:43.660
цялото съдържание е достъпно и безплатно

0:01:43.665,0:01:46.525
под формата на Jupiter-тетрадки

0:01:46.525,0:01:49.800
и това е благодарение на голямата щедрост на

0:01:49.800,0:01:53.300
О'Рейли медии, които ни го позволиха.

0:01:54.220,0:02:00.020
Така че ще може да видите на сайта за курса,

0:02:00.260,0:02:03.000
как да получите достъп до всичко това,

0:02:05.380,0:02:07.280
тук е хранилището на fastbook

0:02:07.580,0:02:10.640
където може да видите цялото проклето нещо

0:02:11.920,0:02:17.300
В момента пише че е чернова, но до момента, когато ще го видите,

0:02:17.580,0:02:21.040
вече няма да е, така че имаме голяма молба, която е ...

0:02:23.110,0:02:25.110
Сделката е следната -

0:02:25.300,0:02:29.580
може да четете това нещо безплатно под формата на Jupyter-тетрадки, но

0:02:30.000,0:02:35.900
така не е толкова удобно, както четенето на Киндл или, знаете, на хартиена книга

0:02:36.360,0:02:41.240
Затова моля не превръщайте материала в PDF, прав ли съм? Моля, не го преобразувайте към

0:02:42.240,0:02:44.680
формат, който е специално за четене

0:02:44.940,0:02:51.160
Защото идеята е, че се надяваме, знаете, че ще купите книгата. Не се

0:02:51.580,0:02:54.180
възползвайте от щедростта на O'Reilly

0:02:54.540,0:02:56.019
като

0:02:56.019,0:02:58.019
създадете нещо, което ...

0:02:58.020,0:03:00.780
знаете, не ви се дава безплатно и

0:03:01.080,0:03:06.060
такъв е и изрично лиценза по който ви осигуряваме достъпа

0:03:07.140,0:03:09.660
Това е основно молба да сме свестни хора

0:03:10.060,0:03:15.120
Ако видите някой, който не е благоприличен човек и краде "книжната" версия на книгата

0:03:15.120,0:03:20.100
Моля кажете им "моля не правете така". Не е хубаво и не бъдете такъв човек.

0:03:21.000,0:03:26.960
Така или иначе, може да четете книгата съвместно с учебната програма

0:03:28.480,0:03:34.140
Има няколко различни версии на тези тетрадки

0:03:38.040,0:03:41.560
Има пълната версия, която

0:03:43.020,0:03:47.200
съдържа целият текст, картинки, всичко

0:03:47.440,0:03:50.200
В действителност написахме

0:03:50.200,0:03:54.500
система, която преобразува тетрадките в печатна книга

0:03:54.740,0:03:58.500
и понякога това изглежда малко странно, например

0:03:58.500,0:04:03.480
ето странно изглеждаща таблица, но ако погледнете в истинската книга

0:04:05.020,0:04:07.540
таблицата се вижда като нормална таблица

0:04:07.720,0:04:11.459
така че понякога ще виждате малки странни части/маркировки

0:04:11.459,0:04:17.939
Добре, те не са грешки. Те са части, където ние добавяме информация, за да помогнем на книгата ни да се превърне истинска хубава книга.

0:04:17.940,0:04:19.940
Така че, просто ги игнорирайте.

0:04:21.070,0:04:24.239
Когато казвам "ние", кои сме ние?

0:04:25.570,0:04:28.749
Важна част от "ние" е

0:04:29.660,0:04:35.860
Силвер. Силвер ми е съавтор за книгата и за версия 2 на библиотеката fastai.

0:04:35.860,0:04:38.500
Така че той е моят съучастник в престъплението

0:04:39.180,0:04:41.080
Другият ключов

0:04:41.090,0:04:43.090
"ние" е

0:04:43.640,0:04:50.000
Рейчъл Томас и така Рейчъл може да дойдеш и да се представиш. Тя е съосновател на fast.ai.

0:04:52.260,0:04:55.740
Здравейте, да, аз съм съосновател на fast.ai, аз съм също

0:04:56.780,0:05:04.630
по-ниска, извинете, по-висока от Джереми и съм основател на Центъра за приложна етика на Университета в Сан Франциско

0:05:05.360,0:05:10.599
Наистина съм развълнуван да бъда част от този курс и ще бъда гласът, който ще чувате да задава въпроси от форумите

0:05:15.050,0:05:20.979
Рейчъл и Силвер също така са хората от тази група, които всъщност разбират математиката. Аз съм завършил философия

0:05:21.830,0:05:26.319
Рейчъл има докторска степен. Силвер е написала 10 книги по математика

0:05:26.900,0:05:29.799
Ако възникнат въпроси по математика, може

0:05:30.320,0:05:32.320
да ги предам към тях

0:05:32.330,0:05:37.059
Но е много хубаво да имаш възможност да работиш с хора, които разбират тази тема толкова добре

0:05:38.360,0:05:40.419
Да. Да Рейчъл. Искаш ли да

0:05:41.990,0:05:48.069
Разбира се, благодаря и както Рейчъл спомена и друга област, където тя

0:05:49.400,0:05:56.199
има експертиза от световна класа е етиката на данните. Тя е учредителният директор на центъра за приложни данни

0:06:00.230,0:06:02.230
В университета на Сан Франциско. Благодаря

0:06:02.720,0:06:09.280
Ще говорим за етика на данните по време на целия курс, защото смятаме, че е много важно

0:06:09.880,0:06:15.700
Така че за тези части, въпреки че по принцип аз ще ги представям, те ще бъдат като цяло базирани на

0:06:15.940,0:06:20.260
работата на Рейчъл, защото тя в действителност знае за какво говори

0:06:21.460,0:06:24.460
Въпреки че благодарение на нея и аз поназнайвам за какво говоря

0:06:25.760,0:06:27.760
Точно така, така е това

0:06:31.040,0:06:37.420
Така че трябва ли да сте тук, има ли някакъв момент, който се опитвате да разберете?

0:06:40.549,0:06:42.549
Да разберете многослойното машинно самообучение

0:06:44.720,0:06:52.160
Така че какво правите тука, има ли смисъл да се опитвате да научите deep learning

0:06:52.400,0:07:01.000
или сте прекалено глупави или нямате достатъчно големи ресурси или каквото и да е, защото това е каквото ни казват много хора

0:07:01.000,0:07:06.360
Казват, че имате нужда от екипи от доктори и огромни центрове за данни, пълни с графични процесори. В противен случай,

0:07:06.889,0:07:08.889
иначе е безсмислено

0:07:09.200,0:07:13.900
Не се притеснявайте. Това изобщо не е вярно. Даже не може да бъде по-далеч от истината. the vast

0:07:14.320,0:07:19.940
Всъщност огромна част  изследвания от световна класа

0:07:20.180,0:07:26.380
и практически проекти на световно ниво са направени от завършили fast.ai,

0:07:27.700,0:07:33.940
проекти базирани на библиотеката fast.ai и други,

0:07:33.940,0:07:37.240
създадени са на едно GPU

0:07:37.460,0:07:42.060
използвайки няколко десетки или няколко стотици примерни записа

0:07:42.060,0:07:48.340
от хора, които нямат познания на студент, завършил техническа специалност

0:07:48.340,0:07:53.860
или в моя случай нямам  изобщо техническо образование. Аз съм завършил специалност философия.

0:07:54.619,0:07:56.599
Така че има,

0:07:56.599,0:07:58.089
както ще видим по време на курса,

0:07:58.089,0:08:03.099
има много и много и много ясни емпирични доказателства, че нямате нужда от много математика

0:08:03.100,0:08:07.820
Нямате нужда от много данни. Не ви трябват много скъпи компютри, за да правите страхотни неща с deep learning.

0:08:08.100,0:08:10.980
Така че, просто останете с нас. Всичко ще е наред

0:08:11.780,0:08:14.140
За да се справите с този курс, трябва да може да програмирате

0:08:15.460,0:08:17.460
За предпочитане знаете как да кодирате в Python

0:08:18.259,0:08:19.989
но ако ползвате други езици

0:08:19.989,0:08:21.989
може да научите Python

0:08:22.069,0:08:28.208
Ако единствените езици, с които работите, са нещо като MATLAB, където сте ги използвали по-скоро като за скриптове за нещо,

0:08:28.939,0:08:31.629
ще ви бъде по тежко,

0:08:32.990,0:08:37.419
но това е нормално. Може да учите Python в процеса на курса

0:08:40.399,0:08:44.318
Има ли някакъв смисъл да учим за deep learning, има ли нещо полезно?

0:08:44.930,0:08:48.729
Ако се надявате да създадете мозък,

0:08:49.700,0:08:51.560
това е AGI

0:08:51.580,0:08:55.600
Не мога да обещая, че ще ви помогна в това

0:08:55.600,0:09:00.120
и AGI означава "artificial general intelligence" изкуствен общ интелект. Благодаря

0:09:00.120,0:09:03.520
Това, което мога да ви кажа обаче, е това във всички тези области

0:09:04.130,0:09:10.900
Deep learning  е най-добрият известен подход, поне за много варианти на всички тези неща

0:09:12.290,0:09:13.850
Така че

0:09:13.850,0:09:17.740
не е преувеличено, че това е полезен инструмент

0:09:17.740,0:09:22.620
Това е полезен инструмент за много и много и много места, изключително полезен инструмент.

0:09:22.620,0:09:26.280
И в много от тези случаи е еквивалентен

0:09:26.280,0:09:31.440
или по-добър от човешкото представяне, поне за определени тесни

0:09:31.820,0:09:35.400
определения за нещата, които хората правят в този тип области

0:09:35.780,0:09:38.380
Така че deep learning доста невероятно

0:09:38.390,0:09:39.260
и ако

0:09:39.260,0:09:45.760
Може да спрете видеото тук, да разгледате и да изберете нещо, което ви изглежда интересно

0:09:45.960,0:09:52.480
и да напишете ключовата дума и deep learning в Google и ще намерите много статии, примери и подобни неща

0:09:54.860,0:09:56.390
Deep learning (многослойното машинно самообучение)

0:09:56.390,0:10:02.559
произлиза от невронните мрежи, както ще видите то е просто един вид

0:10:03.770,0:10:05.770
обучение на невронни мрежи

0:10:06.160,0:10:08.760
дълбоко - с много слоеве, по-нататък ще обясним точко какво означава това.

0:10:09.080,0:10:11.260
Невронните мрежи определено не са нещо ново.

0:10:11.560,0:10:15.240
Водят началото си от поне 1943, когато McCulloch и Pitt's

0:10:15.560,0:10:22.239
създават математичен модел на изкуствен неврон и много се развълнуват докъде може да ги доведе

0:10:23.030,0:10:25.030
След това през 50-те

0:10:25.850,0:10:27.620
Франк Розенблат

0:10:27.620,0:10:29.620
построява на тази основа,

0:10:30.230,0:10:34.900
на практика прави минимални промени на този математичен модел1

0:10:35.540,0:10:41.400
и смята, че с тези фини промени "можем да станем свидетели на раждането на машина, която е способна да възприема

0:10:41.760,0:10:46.060
разпознава и идентифицира заобикалящата я среда без човешко обучение или контрол" и

0:10:46.640,0:10:48.940
надзирава изграждането на това

0:10:49.910,0:10:54.040
изключително нещо, mark 1 перцептрон, в Корнел

0:10:56.270,0:10:58.749
Мисля, че тази снимка е от 1961

0:11:00.050,0:11:06.820
За щастие в наши дни не е нужно да изграждаме невронни мрежи, като пускаме проводници от неврон към неврон,  изкуствен неврон

0:11:07.070,0:11:09.309
но можете да видите идеята

0:11:09.410,0:11:14.200
за какви връзки става дума и в този курс ще чуете думата връзка много често, защото това е всъщност всичко

0:11:16.570,0:11:20.109
След това имаме първата AI (Artificial Intelligence) зима, както е известна, която реално

0:11:20.840,0:11:25.299
До голяма степен се случва, защото професор от MIT на име Марвин Мински

0:11:26.000,0:11:33.520
и Паперт написват книга, наречена "Перцептрон" за изобретението на Розенблат, в която посочват, че един слой от

0:11:33.950,0:11:35.060
тези

0:11:35.060,0:11:37.060
устройства - изкуствени неврони,

0:11:37.280,0:11:39.080
всъщност не може да научи

0:11:39.080,0:11:44.979
някои критични неща, невъзможно е да научат нещо толкова просто като булевия оператор XOR

0:11:46.340,0:11:51.309
В същата книга те показват, че използването на множество слоеве от устройствата всъщност ще отстрани проблема

0:11:51.980,0:11:55.930
хората игнорират, не забелязват тази част от книгата и забелязват само това

0:11:57.020,0:12:01.299
ограничение, и хората в общи линии решихават, че невронните мрежи няма да отидат на никъде и

0:12:02.090,0:12:03.320
те

0:12:03.320,0:12:05.859
до голяма степен изчезват за десетилетия

0:12:06.500,0:12:07.910
до

0:12:07.910,0:12:10.680
По някакъв начин 1986 г., междувременно се случи много,

0:12:11.380,0:12:14.160
но през 1986 г. имаше голямо нещо, което е

0:12:14.900,0:12:21.309
MIT пусна книга, книга от два тома, наречена "Паралелна разпределена обработка" (PDP)

0:12:23.240,0:12:26.740
В което те описаха това нещо, което наричат ​​паралелна разпределена обработка

0:12:27.320,0:12:32.559
където имате куп обработващи единици, които имат някакво състояние на

0:12:32.960,0:12:37.030
активиране и някаква изходна функция, и някакъв

0:12:37.340,0:12:43.689
модел на свързване, и някакво правило за разпространение и някакво правило на активиране, и някакво правило за учене, работещо в среда

0:12:43.960,0:12:48.360
И тогава те описват как нещата, които отговарят на тези изисквания

0:12:48.500,0:12:52.900
може на теория да вършат всякакви невероятни работи

0:12:52.900,0:12:54.999
Това беше резултат от много много

0:12:55.280,0:13:02.619
изследователи, работещи заедно като цяла група, участваща в този проект, в резултат на което се получи тази много важна книга и

0:13:03.080,0:13:09.909
Така че интересното тук за мен е, че ако вие, като преминете през този курс, се върнете и погледнете

0:13:10.280,0:13:18.219
тази снимка, ще видите, че правим точно тези неща, всичко, което учим е, как се прави

0:13:18.830,0:13:20.720
всяко едно от тези

0:13:20.720,0:13:25.959
осем неща.  Интересно е, че те включват околната среда, защото това е нещо, което много често

0:13:26.720,0:13:31.509
учените по теория и анализ на данни пренебрегват. Това е, че ти изграждаш модел, обучаваш го, научил е нещо,

0:13:31.509,0:13:37.269
но в какъв контекст работи? Ще говорим за това доста и през следващите няколко урока.

0:13:39.619,0:13:41.619
Така през 80-те

0:13:42.379,0:13:48.459
по време и след издаване на книгата, хората започнаха да се слагат и този втори слой неврони

0:13:48.859,0:13:52.329
избягвайки проблема на Мински и всъщност

0:13:53.179,0:13:55.179
Показано беше, че

0:13:55.879,0:14:02.079
Математически беше доказано, че чрез добавяне на този допълнителен слой неврони,

0:14:02.629,0:14:08.379
всеки математически модел може да се апроксимира с произволно ниво на точност с тези невронни мрежи

0:14:09.319,0:14:13.599
И така това беше точно обратното на Мински

0:14:13.600,0:14:18.850
Това беше като "ей, знаете, няма нещо, което да не можем да направим", доказуемо няма такова нещо

0:14:19.260,0:14:22.660
И така бяха нещата, когато започнах да се занимавам с невронни мрежи

0:14:23.060,0:14:27.020
Може би бях малко по-късно. Предполагам, че се включвах в началото на

0:14:27.589,0:14:34.898
90-те години и те бяха много широко използвани в промишлеността. Използвах ги за много скучни неща, като целевия маркетинг за банките обслужващи дребни клиенти

0:14:35.989,0:14:41.829
Основно големи компании с много пари, ги използваха и със сигурност  беше вярно, че

0:14:42.289,0:14:49.239
често мрежите са били твърде големи или бавни, за да бъдат полезни. Със сигурност имаше полезни за нещо, но неща, но те

0:14:50.239,0:14:50.829
знаете,

0:14:50.829,0:14:57.758
никога не съм ги чувствал така, сякаш изпълняват обещаното по някаква причина. Това, което не знаех и никой аз

0:14:58.549,0:15:00.230
никой, който лично съм срещал не знаеше, е

0:15:00.230,0:15:08.109
че е имало изследователи, които са показали преди 30 години, че за да се постигнат практически добри резултати, са нужни повече слоеве неврони

0:15:08.809,0:15:16.509
Дори математически, теоретично да можете да получите такава точност, каквато искате, само с един допълнителен слой, за да го направите

0:15:16.970,0:15:24.579
с добри характеристики се нуждаете от повече слоеве. Така че, когато добавите още слоеве към невронна мрежа, вие отивате на дълбоко (deep),

0:15:25.129,0:15:29.918
така че "дълбоко" (в deep learning) не означава нищо  мистично, а просто означава

0:15:30.439,0:15:34.189
повече слоеве. Повече слоеве от добавяне на един допълнителен.

0:15:35.850,0:15:42.200
Благодарение на това невронните мрежи сега достигат своя потенциал, както видяхме в това, в какво  е добро deep learning.

0:15:42.210,0:15:48.139
Така че сега можем да кажем, че Розенблат е бил прав. Ние имаме машина, която е способна

0:15:48.660,0:15:50.220
да възприема,

0:15:50.220,0:15:56.510
разпознава и идентифицира заобикалящата я среда без човешко обучение или контрол. Това определено е вярно

0:15:56.510,0:16:00.229
Не мисля, че има нещо противоречиво в това твърдение, на база на настоящата технология

0:16:00.990,0:16:02.990
Така че ще се научим как да правим това

00:16:04.939,00:16:09.290
Ще учим по точно обратният начин на вероятно цялото

00:16:09.290,00:16:13.770
ни обучение по математика и технически науки.

00:16:13.770,00:16:24.949
Няма да започнем с двучасов урок за сигмоидна функция или с изучаване на линейна

00:16:24.949,00:16:29.750
алгебра или с курс по математически анализ.

00:16:29.750,00:16:37.709
И причината за това е, че хората, които изучават, как да се преподава и учи, са открили, 

00:16:37.709,00:16:41.639
че това не е правилният подход за повечето хора.

00:16:41.639,00:16:50.019
За повечето хора - Ние работим много на база на работата на професор Дейвид Перкинс от Харвард

00:16:50.019,00:16:56.740
и други, които работят по подобни въпроси, които говорят за идеята да се играе цялата

00:16:56.740,00:16:57.740
игра.

00:16:57.740,00:17:01.260
И така, да се играее цялата игра е като, базирайки се на аналогия със спорта, като да

00:17:01.260,00:17:03.949
учиш някой на бейзбол.

00:17:03.949,00:17:10.791
Не ги вкарваш в класна стая и не започваш да ги учиш за физиката на

00:17:10.791,00:17:20.320
параболата, и как да ударят топката, и история на 100 години бейзбол политика в три части,

00:17:20.320,00:17:24.290
след това 10 години по-късно им даваш да гледат игра

00:17:24.290,00:17:27.050
и накрая, 20 години по-късно им даваш да играят играта

00:17:27.050,00:17:31.930
Така се прави един вид при образованието по математика.

00:17:31.930,00:17:37.180
Вместо това, при бейзбола първата стъпка е да се каже, хей, нека идем и погледаме малко бейзбол.

00:17:37.180,00:17:38.180
Какво мислите?

00:17:38.180,00:17:39.180
Забавно беше, нали?

00:17:39.180,00:17:42.060
Виж този играч там ... той изтича натам ... преди това другият хвърли топката ей натам ... хей,

00:17:42.060,00:17:44.080
искаш ли да пробваш да направиш удар?

00:17:44.080,00:17:47.380
Добре, значи ти ще удариш топката и аз ще трябва да опитам да я хвана, след това той трябва

00:17:47.380,00:17:52.940
да тича, да тича натам ... и така от първата стъпка вие играете цялата игра.

00:17:52.940,00:17:58.920
И само да добавя към това, когато хората започват, те често може да нямат пълен отбор или да 

00:17:58.920,00:18:03.620
играят пълните девет подавания, но все пак имат усет какво е играта, нещо като

00:18:03.620,00:18:05.390
 идея за голяма картина.

00:18:05.390,00:18:12.510
Така че има много причини, че това помага на повечето човешки създания, макари и

00:18:12.510,00:18:14.050
не на всеки

00:18:14.050,00:18:19.430
Има малък процент хора, които предпочитат да изграждат нещата от фундамента и

00:18:19.430,00:18:24.270
от принципите, и не е изненадващо, че те са преобладаващи в университетските

00:18:24.270,00:18:28.510
среди, защото хората, които стават учени, са хора, които виреят в 

00:18:28.510,00:18:33.350
преобърнатите (според мен) условия на преподаване на нещата.

00:18:33.350,00:18:40.450
Но извън университетите повечето хора учат най-добре по този начин от горе надолу (от приложението към теорията), където

00:18:40.450,00:18:42.390
започваш с пълния контекст

00:18:42.390,00:18:47.290
Стъпка номер две от седемте принципа, от които ще спомена само първите три,

00:18:47.290,00:18:49.620
е да се направи играта да си струва да се играе.

00:18:49.620,00:18:53.590
Това е като, ако играеш беизбол, да имаш състезание.

00:18:53.590,00:19:00.140
Знаете, трупате точки, опитвате да печелите, събирате отбори от цялата общност

00:19:00.140,00:19:02.350
и хората опитват да се победят един друг.

00:19:02.350,00:19:08.640
Имате табло с победителите, кой има най-висок резултат и подобни. 

00:19:08.640,00:19:14.800
Всичко това е за да сме сигурни, че каквото правим го правим правилно.

00:19:14.800,00:19:23.000
Правим цялото нещо, даваме контекста и създаваме интерес.

00:19:23.000,00:19:30.490
И така, при подходът на fastai за изучаване на deep learning, това означава, че днес ще

00:19:30.490,00:19:33.200
обучаваме модели от начало до край.

00:19:33.200,00:19:38.350
Ние реално ще обучим модели и те няма да са скапани модели.

00:19:38.350,00:19:45.070
Ще бъдат съвременни модели на световно ниво, и ние ще се опитаме да ви накараме

00:19:45.070,00:19:50.910
да създадете собствени съвременни модели още днес или при следващия урок, според това

00:19:50.910,00:19:52.810
как ще се развият нещата.

00:19:52.810,00:19:59.200
Номер три от седемте принципа от Харвард, е да се работи върху трудните части.

00:19:59.200,00:20:10.050
Това е като идеята за практика, целенасочена практика.

00:20:10.050,00:20:19.490
Работа върху трудната част означава, че вие не просто полюшвате бухалката към топката, знаете,

00:20:19.490,00:20:22.340
когато излизате да се размотавате.

00:20:22.340,00:20:27.460
Вие тренирате както трябва, намирате тази част, в която сте най-слаби, установявате

00:20:27.460,00:20:31.340
къде е проблемът и работите дяволски упорито върху него.

00:20:31.340,00:20:39.530
В контекста на дълбокото машинно самообучение, това означава, че нищо няма да претупваме.

00:20:39.530,00:20:40.530
Така ли е?

00:20:40.530,00:20:45.210
До края на този курс, вие вече ще сте ползвали висша математика (математически анализ)

00:20:45.210,00:20:47.400
Ще сте ползвали линейна алгебра.

00:20:47.400,00:20:54.380
Ще сте правили софтуерно инженерство на програмен код.

00:20:54.380,00:21:04.290
Ще практикувате тези неща, които са трудни, така че е необходима упоритост и ангажираност.

00:21:04.290,00:21:11.290
Но да се надяваме, ще разберете защо това има значение, защото преди да започнете да практикувате нещо,

00:21:11.290,00:21:14.470
вие вече ще знаете, защо ви е необходимо, защото вече ще го ползвате.

00:21:14.470,00:21:19.450
Например, за да направите моделът си по-добър, ще трябва да разберете концепцията му.

00:21:19.450,00:21:24.490
За тези от вас, които са свикнали на традиционната университетска среда, това ще изглежда

00:21:24.490,00:21:31.190
доста странно и много хора казват, че съжаляват (след година изучаване на fastai),

00:21:31.190,00:21:37.560
че са прекарали прекалено много време изучавайки теория и недостатъчно време за обучаване на модели

00:21:37.560,00:21:39.500
и писане на код.

00:21:39.500,00:21:43.250
Това е основната обратна връзка, която получаваме от хората, които казват,

00:21:43.250,00:21:44.570
"Бих искал да бях направил нещата различно"

00:21:44.570,00:21:45.790
Това е

00:21:45.790,00:21:53.120
Затова моля опитайте, колкото можете повече, след като сте тук, да следвате този подход.

00:21:53.120,00:21:59.400
Ще ползваме комплект програмни средства ... Извинявай Рейчъл

00:21:59.400,00:22:00.400
Да?

00:22:00.400,00:22:02.510
Трябва да кажа още едно нещо за този подход.

00:22:02.510,00:22:07.390
Мисля, че след като много от нас са прекарали толкова години с традиционният подход за обучение,

00:22:07.390,00:22:12.030
от основите към приложението (bottom-up), промяната може да се усеща в началото много некомфортно.

00:22:12.030,00:22:16.620
Аз все още се чуствам некомфортно с това от време навреме, въпреки че съм отдадена на идеята.

00:22:16.620,00:22:21.850
Част от това е, че трябва да се удържите и да сте в добре и без да знаете 

00:22:21.850,00:22:22.850
подробностите.

00:22:22.850,00:22:28.190
Което според мен може да се почувства много непознато или дори погрешно, когато си нов в това.

00:22:28.190,00:22:31.930
Подобно на: „О, почакай, използвам нещо и не разбирам всяка подробност в основата му"

00:22:31.930,00:22:36.370
Но трябва да се доверите, че ще стигнем до тези подробности по-късно.

00:22:36.370,00:22:39.560
Така че не мога да съчувствам, защото не прекарах много време в това

00:22:39.560,00:22:44.050
Но ще ви кажа това - преподаването по този начин е много, много, много трудно.

00:22:44.050,00:22:49.430
И често се хващам, че прескачам обратно към подхода "първо основите".

00:22:49.430,00:22:51.810
Защото е толкова лесно да кажеш "О, 

00:22:51.810,00:22:52.810
трябва да знаеш това ...

00:22:52.810,00:22:53.810
трябва знаеш това ...

00:22:53.810,00:22:55.140
и тогава можеш да знаеш това"

00:22:55.140,00:22:56.540
Така е много по-лесно да се преподава.

00:22:56.540,00:23:01.760
Така че намирам това много по-предизвикателно за преподаване, но да се надяваме, че си заслужава.

00:23:01.760,00:23:06.980
Прекарахме дълго време да измислим как да представим deep learning в този формат

00:23:06.980,00:23:11.620
Но едно от нещата, които ни помогна, е софтуерът, с който разполагаме.

00:23:11.620,00:23:23.010
Ако не сте използвали Python преди - това е изключитело гъвкав, изразителен и лесен за използване език.

00:23:23.010,00:23:28.210
Има много части от него, които не харесваме, но като цяло обичаме цялостното нещо.

00:23:28.210,00:23:33.790
И ние мислим, и по-важното, болшинството от изследователите и  практикуващите 

00:23:33.790,00:23:38.000
deep learning използват Python.

00:23:38.000,00:23:42.680
Над Python има две библиотеки, които повечето колеги използват днес: PyTorch и

00:23:42.680,00:23:44.140
TensorFlow.

00:23:44.140,00:23:47.550
Тук се случи много бърза промяна.

00:23:47.550,00:23:51.090
Допреди няколко години преподавахме TensorFlow.

00:23:51.090,00:23:54.970
Тогава го използваха всички.

00:23:54.970,00:24:00.370
Най-общо TensorFlow затъна много

00:24:00.370,00:24:05.930
Дойде и този друг софтуер, наречен PyTorch, който беше много по-лесен за използване и много по

00:24:05.930,00:24:15.040
полезен за изследователите и през последните 12 месеца, процентът на статиите на големи

00:24:15.040,00:24:21.290
конференции, които използват PyTorch, е нарастнал от 20% на 80% и обратно, тези които използват

00:24:21.290,00:24:24.960
TensorFlow, е намалял от 80% на 20%

00:24:24.960,00:24:29.030
Така че всички хора, които всъщност изграждат технологията, всички сега използват 

00:24:29.030,00:24:35.340
PyTorch, и знаете, индустрията се движи малко по-бавно, но през следващите година-две

00:24:35.340,00:24:38.900
вероятно ще сте свидетели на подобно нещо и в индустрията.

00:24:38.900,00:24:45.180
Особеното на PyTorch е, че е супер супер гъвкав и наистина е създаден 

00:24:45.180,00:24:52.570
за гъвкавост и дружелюбност за разработчици, със сигурност не е създаден за дружелюбност към начинаещите и

00:24:52.570,00:24:57.950
не е проектиран за, както казваме, няма API на високо ниво, под което разбирам,

00:24:57.950,00:25:05.630
че няма неща, които да улесняват бързото изграждане на неща с помощта на PyTorch.

00:25:05.630,00:25:13.700
За да се справим с този проблем, имаме библиотека, наречена fastai, която стъпва върху PyTorch.

00:25:13.700,00:25:20.330
fastai е най-популярният API на по-високо ниво за PyTorch.

00:25:20.330,00:25:27.520
Тъй като нашите курсове са толкова популярни, някои хора са под погрешното впечатление

00:25:27.520,00:25:34.260
че fastai е създаден за начинаещи или за преподаване.

00:25:34.260,00:25:43.840
Създаден е за начинаещи и за преподаване, както и за практикуващи от индустрията и за изследователи.

00:25:43.840,00:25:50.290
Начинът, по който постигаме това, гарантира, че това е най-добрият API за всички тези хора,

00:25:50.290,00:25:59.340
тъй като използваме нещо, наречено многослоен API и има рецензирана статия, която Силвен

00:25:59.340,00:26:04.600
и аз написахме, която описва как сме го направили и за тези от вас, които са софтуерни инженери,

00:26:04.600,00:26:08.130
това няма да бъде нещо необичайно или изненадващо

00:26:08.130,00:26:12.590
Това са просто напълно стандартни практики от софтуерното инженерство, но практики, които

00:26:12.590,00:26:17.030
не са следвани в нито една позната ни библиотека за deep learning.

00:26:17.030,00:26:24.500
В основни линии много ре-факторинг и разединяване и така, този подход ни позволи

00:26:24.500,00:26:32.410
да изградим нещо, което може да прави изследвания от съвсем ниско ниво, може да правите съвременни

00:26:32.410,00:26:43.850
модели за внедряване и може да правите много лесно, за начинаещи, модели за начинаещи но на световно

00:26:43.850,00:26:47.220
Това е основният софтуерен стек, има и други части софтуер, за които ще учим

00:26:47.220,00:26:49.940
по пътя ни.

00:26:49.940,00:26:54.570
Но основното, което мисля да спомена тук, е, че всъщност няма значение.

00:26:54.570,00:27:01.300
Ако овладеете този софтуерен стек и след това на работа трябва да използвате TensorFlow и Keras,

00:27:01.300,00:27:06.380
ще може да превключите за по-малко от седмица

00:27:06.380,00:27:13.070
Много и много студенти са го правили, и никога не е било проблем.

00:27:13.070,00:27:20.700
Важното е да се научи концепцията и затова ще се фокусираме върху тези концепции

00:27:20.700,00:27:27.870
и като използваме API, което свежда до минимум количеството на помощните работи, които трябва да използвате, ще 

00:27:27.870,00:27:29.730
може да се фокусирате върху елементите, които са важни.

00:27:29.730,00:27:38.150
Конкретните редове код ще отговарят много повече на конкретните концепции, които прилагате.

00:27:38.150,00:27:41.450
Ще ви трябва GPU машина.

00:27:41.450,00:27:49.420
GPU е графичен процесор и по-специално се нуждаете от Nvidia GPU.

00:27:49.420,00:27:55.520
Други марки графични процесори просто не се поддържат добре от никакви библиотеки за Deep Learning.

00:27:55.520,00:27:56.970
Моля, не купувайте такъв.

00:27:56.970,00:28:00.130
Ако вече имате такъв, вероятно не трябва да го използвате.

00:28:00.130,00:28:05.400
Вместо това трябва да използвате една от платформите, които вече сме настроили за вас.

00:28:05.400,00:28:10.410
Просто е огромно разсейване да прекарвате времето си в системна администрация

00:28:10.410,00:28:16.330
на GPU машина, инсталирайки драйвери и т.н.

00:28:16.330,00:28:18.000
И го стартирайте на Линукс

00:28:18.000,00:28:19.000
Моля ви!

00:28:19.000,00:28:22.260
Така правят всички, не само ние, всеки изпълнява кода на Линукс

00:28:22.260,00:28:23.370
Направете живота си лесен

00:28:23.370,00:28:28.200
Достатъчно трудно е да изучавате Deep Learning и без да се налага да си добавяте допълнителни пречки

00:28:28.200,00:28:31.550
знаете, всякакви тайнствени проблеми с хардуерната поддръжка

00:28:31.550,00:28:43.480
Има много безплатни варианти на разположение, затова моля, използвайте ги.

00:28:43.480,00:28:48.280
Ако използвате вариант, който не е безплатен, не забравяйте да изключите виртуалната машина

00:28:48.280,00:28:51.730
Това, което ще стане, е че ще държите сървър, който работи някъде

00:28:51.730,00:28:57.260
другаде по света и ще се свързвате към него от своя компютър, и ще обучавате,

00:28:57.260,00:29:01.500
пускате и създавате модели.

00:29:01.500,00:29:05.980
Това, че затваряте прозореца на браузъра си, не означава, че сървърът ви спира да работи

00:29:05.980,00:29:06.980
 като цяло.

00:29:06.980,00:29:07.980
Разбрахте ли?

00:29:07.980,00:29:11.330
Затова не забравяйте да го изключите, защото в противен случай плащате за него.

00:29:11.330,00:29:16.120
Google Colab е страхотна система, която е безплатна.

00:29:16.120,00:29:18.650
Също така има и версия за платен абонамент

00:29:18.650,00:29:21.200
Бъдете внимателни с Колаб.

00:29:21.200,00:29:26.590
Повечето от останалите системи, които препоръчваме, запазват работата ви автоматично и може

00:29:26.590,00:29:28.460
да се върнете и да продължите по всяко време.

00:29:28.460,00:29:29.460
Colab не.

00:29:29.460,00:29:37.110
Затова не забравяйте да проверите във форумите темата за платформата Colab, за да научите повече

00:29:37.110,00:29:44.020
Като споменах форумите ...

00:29:44.020,00:29:51.970
Форумите са наистина много важни, защото там са всички дискусии уговорки

00:29:51.970,00:29:54.030
и всичко, което се случва.

00:29:54.030,00:29:56.240
Така например, ако искате помощ при настройката

00:29:56.240,00:30:03.820
Знаете, има помощна тема за настройка и можете да разберете, как най-добре да настроите 

00:30:03.820,00:30:09.150
Colab и можете да видите дискусии за него и да задавате въпроси. Моля, не забравяйте

00:30:09.150,00:30:12.310
да търсите, преди да задавате въпроси, нали?

00:30:12.310,00:30:18.620
Защото вероятно е попитано и преди, освен ако не сте един от първите хора, 

00:30:18.620,00:30:22.530
които правят курса.

00:30:22.530,00:30:24.820
И така, след като ...

00:30:24.820,00:30:31.570
И така, първата стъпка е да настроите вашия сървър, като просто следвате инструкциите от

00:30:31.570,00:30:33.620
форумите или от уебсайта на курса.

00:30:33.620,00:30:39.880
И уебсайтът на курса ще има много инструкции стъпка по стъпка за всяка платформа.

00:30:39.880,00:30:44.680
Те ще варират в цената, ще се различават по скорост, наличност и

00:30:44.680,00:30:46.390
така нататък

00:30:46.390,00:30:48.390
След като приключите с прилагане на инструкциите,

00:30:48.390,00:30:57.790
като последна стъпка от инструкциите ще видите нещо такова: 

00:30:57.790,00:31:01.290
папка course v4, т.е. версия четвърта на курса.

00:31:01.290,00:31:04.820
До момента, в който гледате това видео, вероятно ще има още неща  в нея, но ще иима

00:31:04.820,00:31:07.670
NB - означаващо папка с тетрадки (notebooks)

00:31:07.670,00:31:15.260
Така че може да цъкнете върху това и ще видите всички тетрадки за курса

00:31:15.260,00:31:21.060
Това, което искам да направите, е да превъртите до долу и да намерите тази, наречена app Jupyter.

00:31:21.060,00:31:27.760
Цъкнете и там може да започене да учите за Jupyter тетрадките.

00:31:27.760,00:31:30.220
Какво е Jupyter тетрадка?

00:31:30.220,00:31:39.630
Jupyter тетрадка е нещо, където може да пишете неща и да натиснете Shift-Enter,

00:31:39.630,00:31:41.250
и ще ви даде отговор.

00:31:41.250,00:31:47.440
Нещото, което пишете е код на Python и това, което получавате е резултата

00:31:47.440,00:31:48.780
от изпълняване на кода.

00:31:48.780,00:31:52.490
И така, може да сложите каквото и да е на Python.

00:31:52.490,00:31:56.620
X е равно на три по четири

00:31:56.620,00:32:05.240
X плюс едно, и както може да видите, дава ви резултат всеки път, когато има резултат за показване.

00:32:05.240,00:32:10.290
Тези от вас, които сте се занимавали малко с програмиране, ще разпознаете

00:32:10.290,00:32:11.490
REPL

00:32:11.490,00:32:16.370
R-E-P-L, read, evaluate, print, loop - прочети, изчисли, отпечатайте, цикъл

00:32:16.370,00:32:18.940
Повечето езици имат някакъв вид REPL

00:32:18.940,00:32:29.320
REPL на Jupyter тетрадките  е особено интересен, тъй като има неща като заглавия,

00:32:29.320,00:32:34.850
графични изходи, интерактивна мултимедия

00:32:34.850,00:32:37.680
Това е наистина изумителен софтуер.

00:32:37.680,00:32:39.850
Печелил е няколко наистина големи награди

00:32:39.850,00:32:48.200
Бих си помислил, че е най-широко използваният REPL, извън командните обвивки (shell) като bash.

00:32:48.200,00:32:50.280
Това е много мощна система

00:32:50.280,00:32:51.330
Ние я обожаваме

00:32:51.330,00:32:55.940
Написахме цялата си книга в нея, написахме цялата библиотека fastai с нея,

00:32:55.940,00:32:58.970
правим цялото си обучение с нея.

00:32:58.970,00:33:06.780
Това е крайно непознато за хората, които са извършвали по-голямата част от работата си в IDE.

00:33:06.780,00:33:11.070
Трябва да очаквате, че ще се почувства толкова неудобно, колкото може би първия път, когато сте преминали от GUI

00:33:11.070,00:33:13.200
към команден ред

00:33:13.200,00:33:14.200
Различно е

00:33:14.200,00:33:22.080
Така че, ако не сте запознати със системи, базирани на REPL, ви е супер странно.

00:33:22.080,00:33:25.170
Но се придържайте към нея, защото наистина е страхотно.

00:33:25.170,00:33:31.980
Моделът, който се случва тук, е, че тази уеб страница, която разглеждам, ми позволява да въвеждам

00:33:31.980,00:33:37.460
неща, които сървърът да изпълни, и ми показва резултатите от изчисленията, които прави сървърът.

00:33:37.460,00:33:40.170
Значи сървърът е някъде другаде.

00:33:40.170,00:33:42.650
Не работи на моя компютър, ясно?

00:33:42.650,00:33:45.810
Единственото, което работи на компютъра, е тази уеб страница.

00:33:45.810,00:33:53.360
Но като правя нещата, така например, ако кажа, че X е равно на X по три

00:33:53.360,00:33:55.930
това актуализира състоянието на сървъра

00:33:55.930,00:33:56.950
Има това състояние

00:33:56.950,00:34:02.530
Това е каква в момента е стойността на X и така мога да разбера. Сега X е нещо

00:34:02.530,00:34:03.530
различно.

00:34:03.530,00:34:09.669
Така че можете да видите, когато направих този ред тук, той не промени по-ранния X плюс един, нали?

00:34:09.669,00:34:14.730
Така че това означава, че когато гледате Jupyter тетрадка, тя не ви показва текущото

00:34:14.730,00:34:16.559
състояние на сървъра.

00:34:16.559,00:34:21.679
Просто ви показва какво е било това състояние в момента, когато сте го отпечатали

00:34:21.679,00:34:24.889
Това е все едно използвате shell (команден ред) като bash.

00:34:24.889,00:34:26.780
Въвеждате "ls"

00:34:26.780,00:34:28.629
след това изтривате файл

00:34:28.629,00:34:31.990
предишното "ls", което сте отпечатали, не се променя

00:34:31.990,00:34:35.559
Така най общо работят REPL

00:34:35.559,00:34:38.679
включително и този

00:34:38.679,00:34:43.280
Jupyter тетрадките имат два режима.

00:34:43.280,00:34:48.880
Единият е режим "редактиране", който е когато цъкна върху клетка и получа мигащ курсор и мога 

00:34:48.880,00:34:52.190
да се местя наляво и надясно и да въвеждам текст

00:34:52.190,00:34:53.389
Така ли е?

00:34:53.389,00:34:55.740
Няма много клавишни комбинации към този режим.

00:34:55.740,00:35:01.609
Една полезна е "Control" или "Command" + "/" за превръщане в коментар или обратно

00:35:01.609,00:35:07.509
Основната клавишна комбинация е “shift” + “enter” за изпълнение на клетката

00:35:07.509,00:35:09.950
В този момент вече няма мигащ курсор

00:35:09.950,00:35:12.319
Това означава, че вече съм в "команден" режим.

00:35:12.319,00:35:13.640
А не режим на редактиране

00:35:13.640,00:35:17.460
Като отивам нагоре и надолу, избирам различни клетки

00:35:17.460,00:35:23.480
така в команден режим, като се местим, избираме клетки

00:35:23.480,00:35:26.829
и вече има много клавишни комбинации, които можете да използвате.

00:35:26.829,00:35:30.600
Ако натиснете „H“, можете да получите списък с тях.

00:35:30.600,00:35:36.150
И ще видите, че не са като цяло от типа "Control" или "Command"

00:35:36.150,00:35:38.049
с нещо друго, а са просто отделни букви.

00:35:38.049,00:35:41.799
Ако сте използвали Vim ще сте по-запознати с тази идея.

00:35:41.799,00:35:45.680
Например, ако натиснете "C" да копирам и "V" да поставя

00:35:45.680,00:35:47.440
и клетката се копира.

00:35:47.440,00:35:50.769
Или "X" за да я отрежа

00:35:50.769,00:35:55.150
"A" добавя нова клекта отгоре на текущата

00:35:55.150,00:35:58.780
и след това мога да натисна различни цифри, за да създам заглавия

00:35:58.780,00:36:01.890
например клавиш две ще направи заглавие от второ ниво

00:36:01.890,00:36:08.319
И както виждате, мога да въвеждам форматиран текст, не просто код.

00:36:08.319,00:36:15.569
Форматираният текст, който въвеждам е във формат Markdown.

00:36:15.569,00:36:22.990
като това

00:36:22.990,00:36:24.369


00:36:24.369,00:36:26.800


00:36:26.800,00:36:28.880
Така че това е в Markdown

00:36:28.880,00:36:34.950
Ако досега не сте използвали Markdown, това е супер супер полезен начин за писане на форматиран

00:36:34.950,00:36:35.950
текст

00:36:35.950,00:36:38.359
Използва се много, много широко

00:36:38.359,00:36:41.760
Научете го, защото е много удобен

00:36:41.760,00:36:46.390
и ще ви трябва за Jupyter

00:36:46.390,00:36:51.930
Като погледните в тетрадките на нашата книга

00:36:51.930,00:36:57.839
може да видите примери за всякакви видове форматиране и код и неща

00:36:58.839,00:37:05.240
Така че трябва да продължите и да преминете през „app_jupyter“

00:37:05.240,00:37:08.869
и може да видите например, как да създадете графики

00:37:08.869,00:37:10.900
и списъци с неща

00:37:10.900,00:37:12.869
да въвеждате библиотеки

00:37:12.869,00:37:18.430
да показвате картинки и т.н.

00:37:18.430,00:37:25.740
Ако искате да създадете нова тетрадка, може просто да идете на "New" "Python 3" и това

00:37:25.740,00:37:29.940
създава нова тетрадка

00:37:29.940,00:37:35.450
Която по подразбиране е наименована “Untitled”, така че може да я преименувате за да и дадете каквото

00:37:35.450,00:37:38.460
име си харесате

00:37:38.460,00:37:45.480
И ще видите новото име, в списъка тук, "newname".

00:37:45.480,00:37:50.269
Другото, което трябва да знаете за Jupyter е, че е хубав лесен начин да скочите в терминал

00:37:50.269,00:37:51.450
ако знаете, как да използвате терминал

00:37:51.450,00:37:54.509
Разбира се не ви е нужно за този курс или поне за първите неща

00:37:54.509,00:38:08.269
Ако натиснете нов терминал ... и може да видите, че имам терминал

00:38:08.269,00:38:19.140
Едно нещо, което трябва да се отбележи е, че тетрадките са прикрепени към хранилище на Github

00:38:19.140,00:38:21.950
Ако не сте използвали Github преди, всичко е наред,

00:38:21.950,00:38:27.290
но по принцип те са прикачени към сървър, където от време на време ще актуализираме

00:38:27.290,00:38:29.480
тетрадките

00:38:29.480,00:38:33.329
Ще видите на уебсайта на курса, във форума, ще ви кажем как да направите така,

00:38:33.329,00:38:35.890
че да имате най-новите версии.

00:38:35.890,00:38:40.640
Като вземете най-новите версии, не искате да влязат в конфликт или да презапишат вашите

00:38:40.640,00:38:41.640
промени.

00:38:41.640,00:38:50.329
Затова, като започнете да експериментирате, не е лоша идея да изберете тетрадка и да цъкнете дублирай (duplicate)

00:38:50.329,00:38:52.500
и да започнете работата си върху копието.

00:38:52.500,00:38:59.099
Така, когато получите актуализация на последните материали от курса, те няма да развалят

00:38:59.099,00:39:06.089
експериментите, които сте изпълнявали

00:39:06.089,00:39:09.490
Има две важни хранилища, за които трябва да знаете.

00:39:09.490,00:39:20.089
Едното е хранилището fastbook, което видяхме по-рано, което е нещо като пълната книга

00:39:20.089,00:39:26.099
със всички резултати и проза и всичко

00:39:26.099,00:39:30.390
И другото е хранилището course-v4

00:39:30.390,00:39:34.690
и тук е съвсем същата тетрадка

00:39:34.690,00:39:42.130
като за тази сме премахнали целият текст и всички картинки и всички резултати

00:39:42.130,00:39:46.210
и сме оставили само заглавията и кода

00:39:46.210,00:39:51.029
В този случай може да видите някои резултати, защото току що изпълних кода, но за по-голямата част

00:39:51.029,00:39:53.410
няма да има никакви

00:39:53.410,00:39:56.300
Не, не, предполагам че сме оставили резултати

00:39:56.300,00:39:58.009
Не съм сигурен, дали да ги запазя или не

00:39:58.009,00:40:01.849
Така че може да видите или да не видите резултати

00:40:01.849,00:40:04.259
Главната идея е

00:40:04.259,00:40:10.480
това да е версията, с която да искате да експериментирате

00:40:10.480,00:40:15.170
защото един вид ви кара да мислите, например какво ще стане като изпълнявате всяка стъпка,

00:40:15.170,00:40:18.799
вместо просто да четете и да изпълнявате без да мислите.

00:40:18.799,00:40:24.059
Искаме да го правите в малко по-гола среда в която мислите

00:40:24.059,00:40:28.859
какво казва книгата, защо това става така и ако забравите нещо, тогава

00:40:28.859,00:40:31.321
може да се върнете обратно към книгата

00:40:31.321,00:40:36.910
Другото, което трябва да се спомене, е че както course-v4 версията, така и fastbook версията

00:40:36.910,00:40:42.000
имат въпросник

00:40:42.000,00:40:46.529
И доста хора ни казаха, по време на прегледи и подобни, че

00:40:46.529,00:40:49.990
всъщност първо четат въпросника.

00:40:49.990,00:40:57.869
Прекарахме много, много седмици в изготвяне на въпросника, Силвен и аз

00:40:57.869,00:41:04.380
И причината за това е, че се опитваме да измислим, какво искаме от вас

00:41:04.380,00:41:07.680
да усвоите от всяка тетрадка

00:41:07.680,00:41:10.029
Така че може първо да прочетете въпросника

00:41:10.029,00:41:12.150
Да видите, какви са нещата, които според нас са важни

00:41:12.150,00:41:14.940
Какви са нещата, които трябва да знаете, преди да продължите.

00:41:14.940,00:41:18.859
Така че вместо да имате обобщен раздел в края, който казва "накрая трябва да

00:41:18.859,00:41:24.920
знаете ... дъра-бъра ...", вместо това имаме въпросник, който прави същото, така че моля постарайте се

00:41:24.920,00:41:27.730
да направите въпросника преди да се прехвърлите на следващата глава.

00:41:27.730,00:41:31.600
Не е нужно да разберете всичко правилно и в повечето случаи, да отговорите на въпросите е

00:41:31.600,00:41:37.999
толкова просто, колкото да се върнете в тази част на тетрадката и да прочетете текста, но ако сте 

00:41:37.999,00:41:43.289
изпуснали нещо, върнете се назад и го прочетете, защото това са нещата, които приемаме, 

00:41:43.289,00:41:44.960
че ще знаете

00:41:44.960,00:41:50.420
Така че, ако не знаете тези неща, преди да продължите, това може да доведе до разочарование.

00:41:50.420,00:41:57.499
След тези уговорки, ако все пак блокирате, след няколко опита продължете към следващата глава

00:41:57.499,00:42:00.809
направете две, три или повече глави и се върнете обратно

00:42:00.809,00:42:04.480
може би до момента, в който сте минали още няколко глави, ще получите малко повече

00:42:04.480,00:42:05.480
перспектива.

00:42:05.480,00:42:13.099
Опитваме се да дообясняваме нещата по няколко пъти по различни начини, така че всичко е наред, когато сте опитали

00:42:13.099,00:42:17.329
и сте се закучили, тогава може да опитате да продължите.

00:42:17.329,00:42:26.410
И така, нека опитаме да пуснем първата част на тетрадката.

00:42:26.410,00:42:37.490
Намираме се в 01_intro, това е глава 1 и това е първата клетка

00:42:37.490,00:42:45.481
Така че кликвам върху клетката и ... по подразбиране всъщност ще има заглавка в лентата с инструменти,

00:42:45.481,00:42:46.481
както може да видите

00:42:46.481,00:42:47.481
може да я показвате или скривате

00:42:47.481,00:42:53.640
Аз лично винаги ги оставям скрити и така, за да изпълните клетката, трябва или да цъкнете на Play,

00:42:53.640,00:42:56.940
бутонът за пускане, или както споменах, да натиснете клавиши Shift-Enter.

00:42:56.940,00:43:03.349
В случая, просто ще цъкна и, както виждате, появява се тази звездичка, което ни казва

00:43:03.349,00:43:07.880
"Аз работя" и може да видите новоизскочилата лента за напредък. И това ще отнеме

00:43:07.880,00:43:15.680
няколко секунди, и докато работи, ще отпечата някакви резултати

00:43:15.680,00:43:20.740
Не очаквайте да получите съвсем същите резултати като нашите, има определена случайност свързана с

00:43:20.740,00:43:23.779
обучаването на модел и това е нормално.

00:43:23.779,00:43:26.530
Не очаквайте да получите и съвсем същото време като нас.

00:43:26.530,00:43:32.510
Ако първата клетка отнеме повече от пет минути, освен ако нямате найстина старо GPU, това вероятно е

00:43:32.510,00:43:33.510
лош знак.

00:43:33.510,00:43:38.609
Може да се прехвърлите към форумите и да потърсите, какво не е наред или може би

00:43:38.609,00:43:43.400
се опитвате да използвате Windows, който наистина не работи особено добре с това към момента.

00:43:43.400,00:43:45.210
Не се притеснявайте, че не знаем какво прави кода все още

00:43:45.210,00:43:52.410
Просто се убеждаваме, че можем да обучим модел. И така, ето ни, свърши да работи

00:43:52.410,00:43:58.079
и както може да видите, отпечата се някаква информация, в този случай ми показва,

00:43:58.079,00:44:05.269
че има грешка (error rate) 0.005 при правенето на нещо.

00:44:05.269,00:44:06.569
Какво е нещото, което прави?

00:44:06.569,00:44:14.089
Това, което прави е, че взема набор от данни (dataset), извикваме данните за домашни любимци,

00:44:14.089,00:44:18.849
което е набор от снимки на котки и кучета.

00:44:18.849,00:44:25.829
И се опитва да разбере; кои са котки и кои са кучета.

00:44:25.829,00:44:32.599
И както можете да видите, след около по-малко от минута, той е в състояние да направи това с

00:44:32.599,00:44:34.809
0.5% грешка

00:44:34.809,00:44:37.039
Така че може да го направи почти перфектно

00:44:37.039,00:44:39.509
И така, обучихме първия си модел!

00:44:39.509,00:44:40.539
Нямаме идея как

00:44:40.539,00:44:41.799
не знаем какво правим

00:44:41.799,00:44:44.259
но наистина обучихме модел.

00:44:44.259,00:44:46.559
Това е добро начало.

00:44:46.559,00:44:51.309
И както виждате, можем да обучаваме модели доста бързо на един компютър.

00:44:51.309,00:44:55.089
каквито много може да получите безплатно

00:44:55.089,00:45:00.869
Още нещо да отбележа, ако имате Mac ... няма значение дали имате Windows,

00:45:00.869,00:45:05.069
Mac или Linux при използване на браузър,

00:45:05.069,00:45:11.470
но ако имате Mac, моля не се опитвайте да използвате GPU-то

00:45:11.470,00:45:16.150
Всъщност Mac и Apple дори вече не поддържат Nvidia GPU

00:45:16.150,00:45:19.470
Така че това няма да е добрър вариант

00:45:19.470,00:45:20.869
Така че придържайте се към Линукс

00:45:20.869,00:45:25.010
Ще ви направи живота много по-лесен

00:45:25.010,00:45:30.420
И така, първото нещо, което трябва да направим, е да го пробваме

00:45:30.420,00:45:34.750
Така че, ако твърдя, че сме обучили модел, който може да подбира котки от кучета.

00:45:34.750,00:45:37.640
Нека се уверим, че можем.

00:45:37.640,00:45:41.859
Вижте тази клетка

00:45:41.859,00:45:42.859
Интересно е,

00:45:42.859,00:45:43.859
нали?

00:45:43.859,00:45:47.940
Създали сме widget.FileUpload() обект и сме го показали

00:45:47.940,00:45:50.690
и това ни показва бутон за кликване

00:45:50.690,00:45:52.619
Както ви казах, нова е необикновен REPL

00:45:52.619,00:45:55.319
можем дори да създаваме GUI (графичен потребителски интерфейс) в този REPL

00:45:55.319,00:45:58.359
Ако кликна на този бутон

00:45:58.359,00:46:00.170
Мога да избера котка


00:46:04.130,00:46:11.230
и сега мога да превърна качените данни в изображение

00:46:11.230,00:46:14.319
има котка

00:46:14.319,00:46:22.510
и мога да изпълня predict (прогнозирай), и това е котка

00:46:22.510,00:46:26.400
С вероятност 99.96%.

00:46:26.400,00:46:29.910
Виждате, току що качихме снимка, която сме избрали

00:46:29.910,00:46:30.930
Така че може да пробвате и вие

00:46:30.930,00:46:31.930
Така ли е?

00:46:31.930,00:46:32.930
Вземете снимка на котка

00:46:32.930,00:46:35.579
Намерете от Интернет или идете и направете сами снимка

00:46:35.579,00:46:38.910
и не забравяйте да получите снимка на котка

00:46:38.910,00:46:43.520
Това е нещо, което може да разпознава снимки на котки, а не рисунки на котки.

00:46:43.520,00:46:46.940
и както ще видим, по време на курса,

00:46:46.940,00:46:52.050
този вид модели могат да научат само вида информация, която сте им дали

00:46:52.050,00:46:57.130
и до този момент сме дали, както ще видите, само снимки на котки.

00:46:57.130,00:47:06.700
Не анимационни котки, не нарисувани котки, не абстрактни изображения на котки, а просто снимки.

00:47:06.700,00:47:11.470
Сега ще погледнем, какво всъщност е станало тук?

00:47:11.470,00:47:15.930
Както ще видите след момент, тук не получаваме добра информация 

00:47:15.930,00:47:26.259
Ако видите това във вашата тетрадка, трябва да идете до: file, trust notebook.

00:47:26.259,00:47:30.559
и това казва на Jupyter, че е позволено да изпълнява кода, необходим за визуализиране на неща

00:47:30.559,00:47:33.509
за да е сигурно, че няма проблем със сигурността

00:47:33.509,00:47:35.880
И така, вече ще видите резултата

00:47:35.880,00:47:39.880
Понякога ще виждате странен код като този

00:47:39.880,00:47:43.609
Това е кой, който създава изходни резултати

00:47:43.609,00:47:46.349
Понякога скриваме този код,

00:47:46.349,00:47:47.800
понякога го показваме,

00:47:47.800,00:47:51.940
и казано най-общо, може просто да игнорирате такива неща и да се съсредоточите върху това, което следва

00:47:51.940,00:47:52.940
като изход.

00:47:52.940,00:47:54.300
Няма да минавам през тези

00:47:54.300,00:48:00.660
Вместо това ще разгледаме същите неща от слайдовете

00:48:00.660,00:48:04.710
И така, това което правим е машинно самообучение

00:48:04.710,00:48:07.750
Deep Learning е вид машинно самообучение.

00:48:07.750,00:48:09.170
Какво е машинно самообучение?

00:48:09.170,00:48:16.070
Машинното самообучение е просто, както и стандартното програмиране, то е начин да се накарат компютрите да правят нещо.

00:48:16.070,00:48:22.250
Но в случая е доста трудно да разбереш как да използваш нормално програмиране за да разпознаеш

00:48:22.250,00:48:24.000
снимки на кучета от снимки на котки.

00:48:24.000,00:48:28.319
Как да създадеш циклите, да присвоиш променливите, условните констукции

00:48:28.319,00:48:31.789
необходими за създаване на програма, която разпознава кучета от котки на снимки

00:48:31.789,00:48:33.190
Това е страшно сложно

00:48:33.190,00:48:34.589
Много, много сложно

00:48:34.589,00:48:41.420
Толкова трудно, че до ерата на Deep Learning, никой наистина нямаше модел, който да е донякъде точен

00:48:41.420,00:48:43.910
при тази очевидно лесна задача.

00:48:43.910,00:48:46.970
Защото не можем да напишем необходимите стъпки

00:48:46.970,00:48:51.369
Обикновено, пишем функция, която приема някакви входни данни, преминава през 

00:48:51.369,00:48:52.369
нашата програма

00:48:52.369,00:48:55.569
и дава някакви резултати

00:48:55.569,00:49:02.530
Тази обща идея, при която програмата е нещо, което ние пишем (стъпките)

00:49:02.530,00:49:06.970
изглежда не работи добре за неща, като разпознаване на снимки.

00:49:06.970,00:49:12.470
Така през 1949 г. някой на име Артър Самуел започва да се опитва да измисли начин за решаване

00:49:12.470,00:49:16.030
на проблеми като разпознаване на снимки на котки и кучета.

00:49:16.030,00:49:23.000
И през 1962 г. той описа начин за това.

00:49:23.000,00:49:26.270
Най-напред той описа проблема: „Програмирането на компютър 

00:49:26.270,00:49:31.070
за този вид изчисления е в най-добрия случай трудна задача,

00:49:31.070,00:49:37.589
поради необходимостта да се изписва всяка незначителна стъпка от процеса в мъчителни подробности.

00:49:37.589,00:49:42.290
Компютрите са гигантски дебили, което всички ние, програмистите, напълно го признаваме."

00:49:42.290,00:49:46.769
Така че той казва, нека не казваме на компютъра точните стъпки, а да му дадем примери 

00:49:46.769,00:49:50.460
от проблема за решаване и да намери сам, как да го реши.

00:49:50.460,00:49:56.269
И така, до 1961 г. той е изградил програма за шашки, която е победила щатският шампион в Кънектикът,

00:49:56.269,00:50:03.450
не като указва стъпките, които да се предприемат, за да се играят шашки, а като прави това -

00:50:03.450,00:50:09.990
което е "организиране на автоматични начини за проверка на ефективноста на присвоените тегла

00:50:09.990,00:50:15.690
от гледна точка на реално постигнатия резултат и на механизъм за промяна на присвоените тегла, така че да се 

00:50:15.690,00:50:19.019
максимизират резултатите."

00:50:19.019,00:50:21.680
Това е ключовото изречение.

00:50:21.680,00:50:24.440
И то е доста сложно изречение, така че можете да му отделите известно време.

00:50:24.440,00:50:32.200
Основната идея е следната: вместо да казваме входни данни (inputs) за програмата и след това изходни резултати (outputs)

00:50:32.200,00:50:36.430
нека имаме входни данни - и да казваме на програмата модел -

00:50:36.430,00:50:38.140
имаме същата основна идея

00:50:38.140,00:50:40.349
вход - модел - резултати

00:50:40.349,00:50:43.760
и след това ще имаме второ нещо, наречено тегла

00:50:43.760,00:50:50.569
И така,, основната идея е, че този модел е нещо, което създава резултати не само на база,

00:50:50.569,00:50:58.410
в случая, на състоянието на таблото с шашки, но и на база на някакво множество от тегла или параметри,

00:50:58.410,00:51:02.320
които описват, как ще работи моделът.

00:51:02.320,00:51:09.039
Идеята е, ако можем да изредим всички възможни начини за игра на шашки,

00:51:09.039,00:51:14.130
и след това опишем всеки един от тези начини, използвайки някакво множество от параметри, или както Самуел

00:51:14.130,00:51:15.830
ги нарича, тегла.

00:51:15.830,00:51:21.690
След това, ако имаме начин да проверим колко ефективно е текущото присвояване на тегла от гледна точка

00:51:21.690,00:51:27.549
на резултата, с други думи, дали конкретната от изредените стратегии за игра

00:51:27.549,00:51:33.140
на шашки приключва с победа или загуба на играта, и след това начин за промяна на теглата,

00:51:33.140,00:51:35.599
така че да се максимизират резултатите.

00:51:35.599,00:51:40.710
Тогава нека да опитаме да увеличим или намалим всяко едно от тези тегла, едно по едно,

00:51:40.710,00:51:45.190
за да видим, дали има леко по-добър начин за игра на шашки, и след това да го повторим същото

00:51:45.190,00:51:51.950
много, много пъти, и евентуално такава процедура може да се направи изцяло автоматична, и тогава

00:51:51.950,00:51:58.030
така програмирана машина ще може да учи от своя опит, така че този кратък параграф

00:51:58.030,00:52:00.200
е нещото.

00:52:00.200,00:52:05.650
Това е машинно самообучение, начин за създаване на програми, при който те учат,

00:52:05.650,00:52:08.000
вместо да се програмират.

00:52:11.349,00:52:16.930
Ако имаме такова нещо, тогава в общи линии ще имаме нещо, което изглежда така:

00:52:16.930,00:52:22.549
имате входни данни и тегловни коефициенти подавани към модела, който създава резултати, например печелите

00:52:22.549,00:52:26.769
или губите, и мярка за качеството на резултата.

00:52:26.769,00:52:30.349
Припомнете си, това беше тази ключова стъпка и след това втората ключова стъпка е начин за актуализиране 

00:52:30.349,00:52:35.609
на теглата на база измереното качество на резултата и след това може да направите цикъл през този процес

00:52:35.609,00:52:43.450
и да създадете и обучите модел за машинно самообучение, така че това е абстрактната идея

00:52:43.450,00:52:49.260
След като сме тренирали модела известно време, ще ни дава комплект тегловни коефициенти, който е доста добър;

00:52:49.260,00:52:55.089
вече можем да забравим начинът, по който е бил обучен и имаме нещо, което е

00:52:55.089,00:53:02.359
точно като това, освен че думата програма сега е заменена с сумата модел

00:53:02.359,00:53:07.239
И така, обучен модел може да се използва също като всяка друга компютърна програма.

00:53:07.239,00:53:13.509
Идеята е, че създаваме компютърна програма не като поставяме необходимите стъпки

00:53:13.509,00:53:19.619
за изпълнение на задачата, а като я обучаваме да научи да изпълнява задачата, в края на което пак имаме просто

00:53:19.619,00:53:26.759
друга програма. Това е така нареченият логически извод (inference), да се използва обучен модел

00:53:26.759,00:53:37.980
като програма за да изпълнява задачи, като например игра на шашки. И така, машинното самообучение е обучаване на програми, разработени

00:53:37.980,00:53:43.309
като се дава възможност на компютъра да се учи от опита си, вместо ръчно да се програмират отделните стъпки.

00:53:43.309,00:53:53.640
Как бихте направили това за разпознаване на изображение, какъв е този модел и този набор от тегла,

00:53:53.640,00:53:59.700
такива, че като ги променяме да получаваме все по-добро разпознаване на котки спрямо кучета

00:53:59.700,00:54:02.210
Имам предвид, че за шашките

00:54:02.210,00:54:06.780
не е толкова трудно да си представим, как може един вид да изброите, в зависимост от различни

00:54:06.780,00:54:11.289
видове „колко далеч е парчето на противника“, "какво трябва да направите

00:54:11.289,00:54:12.289
в тази ситуация",

00:54:12.289,00:54:16.079
"как трябва да претеглиш защитните спрямо агресивните стратегии" и други

00:54:16.079,00:54:20.410
Изобщо не е очевидно, как трябва да се направи това при разпознаване на изображения.

00:54:20.410,00:54:29.240
Затова, това от което се нуждаем е някаква функция за тук, която да е толкова гъвкава, че има

00:54:29.240,00:54:33.210
множество тегла, които могат да я накарат да направи всичко

00:54:33.210,00:54:40.059
Най-гъвкавата възможна функция в света. Оказва се, че има такова 

00:54:40.059,00:54:41.059
нещо

00:54:41.059,00:54:44.140
Това е невронната мрежа

00:54:44.140,00:54:50.329
Ще опишем точно каква е тази математическа функция в следващите уроци.

00:54:50.329,00:54:56.160
За да я използваме реално няма значение, каква математическа функция е тя.

00:54:56.160,00:55:03.631
Това е функция, която, казваме, е „параметризирана“
под някакъв набор от тегла, с което имам предвид,

00:55:03.631,00:55:12.259
че като давам различни набори тегла, тя изпълнява различни задачи, и на практика може на изпълни всяка

00:55:12.259,00:55:17.970
възможна задача. Така наречената теорема за универсалното приближение ни казва, че математически доказуемо, 

00:55:17.970,00:55:26.319
тази функция може да реши всеки проблем, който е решим, с произволно ниво на точност.

00:55:26.319,00:55:28.589
само ако намерите правилният набор от тегловни коефициенти.

00:55:28.589,00:55:33.210
Което е вид преформулиране на описаното по-рано в това, как се справяме с

00:55:33.210,00:55:39.700
проблема на Мински (Марвин Мински). И така, невронните мрежи са толкова гъвкави, че ако може

00:55:39.700,00:55:44.609
да намерите правилният набор от коефициенти, те могат да решат всеки проблем, включително "Това котка ли е

00:55:44.609,00:55:46.289
или е куче?"

00:55:46.289,00:55:51.130
Така че това означава, че трябва да насочите усилията си към процеса на обучение, т.е. намиране

00:55:51.130,00:55:57.010
на добри тегла или присвояване на добри тегла по терминологията на Самуел. 

00:55:57.010,00:55:59.770
И как го правите това?

00:55:59.770,00:56:09.239
Искаме напълно общ начин да правим това, да променяме теглата въз основа на някаква мярка за

00:56:09.239,00:56:14.200
качеството на работа, като например колко е добър в разпознаване на котки спрямо кучета.

00:56:14.200,00:56:16.839
За наше щастие, оказва се че такова нещо съществува!

00:56:16.839,00:56:21.539
И това нещо се нарича stochastic gradient descent или SGD (стохастично градиентно спускане)

00:56:21.539,00:56:26.540
Отново, ще видим точно как това работи, ще го създадем сами от нулата, но

00:56:26.540,00:56:28.529
засега няма нужда да се тревожим за това.

00:56:28.529,00:56:34.210
Само ще ви кажа, че и SGD, и невронните мрежи изобщо не са 

00:56:34.210,00:56:35.210
математически сложни

00:56:35.210,00:56:38.829
Те са почти изцяло сумирания и умножения.

00:56:38.829,00:56:45.109
Номерът е, че имаме много от тях - милиарди от тях, много повече, отколкото интуитивно можем

00:56:45.109,00:56:46.109
да възприемем.

00:56:46.109,00:56:52.940
Могат да правят изключителни неща, но не са ракетна наука.

00:56:52.940,00:56:58.609
Не са сложни неща и ще видим точно как работят.

00:56:58.609,00:57:03.049
Това е версията на Артур Самуел

00:57:03.049,00:57:08.580
В наши дни не използваме баш същата терминология, но използваме съвсем същата идея.

00:57:08.580,00:57:12.660
Функцията, която се намира по средата,

00:57:12.660,00:57:14.549
наричаме я архитектура

00:57:14.549,00:57:20.779
Архитектура е функцията, чиито коефициенти настройваме, за да я накараме да върши нещо

00:57:20.779,00:57:24.190
Това е архитектурата, това е функционалната форма на модела.

00:57:24.190,00:57:28.849
Понякога хората казват модел и имат предвид архитектура, така че не позволявайте това да ви обърка особено

00:57:28.849,00:57:30.559
Но правилната дума е архитектура.

00:57:30.559,00:57:34.619
Не ги наричаме тегла (тегловни коефициенти), наричаме ги параметри

00:57:34.619,00:57:40.410
Теглата имат специално значение, това са особен вид параметри

00:57:40.410,00:57:46.609
Нещата, които излизат от модела, архитектурата с параметрите, наричаме ги

00:57:46.609,00:57:49.809
прогнози (predictions)

00:57:49.809,00:57:55.660
Прогнозите се базират на два вида входна информация (inputs): независимите променливи, това са данните,

00:57:55.660,00:58:03.309
като снимките на котки и кучета, и зависими променливи, още известни като етикети (labels)

00:58:03.309,00:58:07.400
което е нещото, казващо ни "това е котка", "това е куче", "това е

00:58:07.400,00:58:08.400
котка".

00:58:08.400,00:58:09.779
Това ви е входа

00:58:09.779,00:58:12.769
Резултатите са прогнозите.

00:58:12.769,00:58:18.670
Мярката за качество на работа, използвайки думите на Артур Самуел, е известна като загуба (loss)

00:58:18.670,00:58:24.020
Загубата се изчислява от етикетите и от прогнозите и след това има

00:58:24.020,00:58:26.720
актуализиране в обратна посока към параметрите.

00:58:26.720,00:58:33.210
Това е същата схема, която вече видяхме, но са сложени думите, които ще използваме

00:58:33.210,00:58:34.210
в наши дни.

00:58:34.210,00:58:40.039
И така, тази картина, ако сте забравили, ако кажа, това са параметрите, използвани

00:58:40.039,00:58:44.220
за тази архитектура да създаде модел, може да се върнете и да си припомните, какво означават.

00:58:44.220,00:58:45.220
Какво са параметрите (parameters)?

00:58:45.220,00:58:46.500
Какво са прогнозите (predictions)?

00:58:46.500,00:58:47.500
Какво е загубата (loss)?

00:58:47.500,00:58:53.970
Загубата е някаква функция, коя измерва работата на модела по такъв начин, 

00:58:53.970,00:58:56.790
че можем да актуализираме параметрите.

00:58:56.790,00:59:06.170
Важно е да отбележим, че Deep Learning и машинното самообучение не са магия.

00:59:06.170,00:59:13.380
Модел може да се създаде само, когато имате данни с примери с нещата, за които

00:59:13.380,00:59:14.869
се опитвате да научите. 

00:59:14.869,00:59:22.030
Моделът може да се обучи да работи само със закономерности, които сте видели във входните данни използвани за обучението му.

00:59:22.030,00:59:27.109
Така че, ако нямаме скици на котки и кучета, тогава никога няма да има

00:59:27.109,00:59:32.519
актуализиране на параметрите, което ще направи архитектурата, по точно архитектурата и

00:59:32.519,00:59:34.420
параметрите заедно представляват модела,

00:59:34.420,00:59:39.650
Та да кажем моделът, която ще направи моделът по-добър в прогнозиране на скици на котки

00:59:39.650,00:59:43.799
и кучета, защото никога няма да има такива аткуализации на теглата, защото никога не са получени

00:59:43.799,00:59:46.680
такива входни данни.

00:59:46.680,00:59:51.239
Забележете също така, че този подход за обучение създава единствено прогнози.

00:59:51.239,00:59:54.319
Не ви казва какво да правите с тях

00:59:54.319,00:59:58.019
Това ще бъде много важно, когато мислим за неща, като система за даване на препоръки

00:59:58.019,01:00:01.230
от типа какъв продукт препоръчваме на някого.

01:00:01.230,01:00:04.950
Ами не знам, ние не правим това, нали?

01:00:04.950,01:00:09.759
Ние мжем да предвидим какво ще каже някой за продукт, който сме му показали, но 

01:00:09.759,01:00:11.140
не създаваме действия.

01:00:11.140,01:00:12.310
Създаваме прогнози.

01:00:12.310,01:00:16.619
Това е супер важна разлика за разпознаване.

01:00:16.619,01:00:22.470
Не е достатъчно само да има примери за входни данни като снимки на кучета и котки.

01:00:22.470,01:00:26.309
Нищо не можем да направим без етикети.

01:00:26.309,01:00:31.359
Много често, организациите казват: "нямаме достатъчно данни".

01:00:31.359,01:00:35.150
В повечето случаи имат предвид: "нямаме достатъчно категоризирани данни (labelled data)"

01:00:35.150,01:00:39.549
Защото, ако компанията се опитва да прави нещо с Deep Learning, често това е защото 

01:00:39.549,01:00:43.180
се опитват да автоматизират или подобрят нещо, което вече правят.

01:00:43.180,01:00:48.420
Това означава, че по определение, те имат данни за това нещо или имат начин за събиране на данни

01:00:48.420,01:00:49.420
за това нещо

01:00:49.420,01:00:50.420
Защото те го правят,

01:00:50.420,01:00:51.420
нали?

01:00:51.420,01:00:55.089
Но често трудната част е поставянето на етикети

01:00:55.089,01:00:57.569
Например, в медицината

01:00:57.569,01:01:00.789
Ако се опитваш да създадеш модел за радиология

01:01:00.789,01:01:06.579
Почти сигурно можете да получите много медицински снимки за почти всичко, за което се сетите

01:01:06.579,01:01:11.769
Но може да е много трудно да ги маркирате според злокачествеността на тумор или според това,

01:01:11.769,01:01:18.480
дали има менингиом или не, или каквото и да е, защото този вид етикети не са непременно

01:01:18.480,01:01:24.289
запазени по стуктуриран начин, поне в медицинската система на САЩ.

01:01:24.289,01:01:31.700
Така че това е важна разлика, която наистина се отразява на вашия вид стратегия.

01:01:31.700,01:01:40.000
След това, както видяхме от книгата PDP, моделът работи в някаква среда.

01:01:40.000,01:01:44.420
Пускате го и правите нещо с нещо

01:01:44.420,01:01:50.640
И така, тази част от PDP рамката е изключително важна.

01:01:50.640,01:01:53.769
Имате модел, който всъщност прави нещо.

01:01:53.769,01:01:59.069
Например, изградили сте прогнозиращ модел на полицейския контрол, който предвижда, не препоръчва действия, а

01:01:59.069,01:02:02.460
предвижда къде ще бъде извършен арест.

01:02:02.460,01:02:06.670
Това е нещо, което много юрисдикции в САЩ използват.

01:02:06.670,01:02:10.809
Прогнозата е въз основа на данни и на базата на етикетирани данни.

01:02:10.809,01:02:20.779
И в този случай всъщност ще се използват
(в САЩ например) данни къде, ... мисля че

01:02:20.779,01:02:25.099
в зависимост дали сте черен или бал, черните хора в САЩ, мисля че са арестувани

01:02:25.099,01:02:31.480
около седем пъти по-често, примерно за притежание на марихуана, от белите

01:02:31.480,01:02:37.579
въпреки че реалната консумация на марихуана е приблизително еднаква за двете

01:02:37.579,01:02:38.579
популации

01:02:38.579,01:02:42.079
Така че, ако започнете с изместени данни (biased data) и изградите прогнозиращ модел на полицейския контрол,

01:02:42.079,01:02:49.430
Прогнозите ще казват "ей, ще намерите някой за арестуване ... тук!" на база

01:02:49.430,01:02:50.430
изкривени данни.

01:02:50.430,01:02:56.279
Затова служителите на реда могат да решат да съсредоточат полицейската си дейност върху зоните,

01:02:56.279,01:02:58.039
където се случват прогнозите

01:02:58.039,01:03:01.940
В резултат, ще намерят още хора за арестуване

01:03:01.940,01:03:05.430
и ще използват тези данни за да захранят модела,

01:03:05.430,01:03:09.789
който сега ще установи: "ха, има още повече хора, които трябва да бъдат арестувани

01:03:09.789,01:03:12.640
в кварталите на черните", и това ще продължи

01:03:12.640,01:03:17.000
Това е пример на това, как моделът си взаимодейства със средата за да създаде т.нар.

01:03:17.000,01:03:19.460
положителна обратна връзка,

01:03:19.460,01:03:23.930
при която, колкото повече използваме модела, толкова по изместени (изкривени - biased) стават данните, което прави модела дори още

01:03:23.930,01:03:26.440
по изместен и така нататък.

01:03:26.440,01:03:32.299
И така, едно от нещата, с които трябва да сме особено внимателни при машинното самообучение, е да се разбере, 

01:03:32.299,01:03:38.009
как всъщност се използва този модел и какви неща могат да се случат, в резултат

01:03:38.009,01:03:39.009
на това.

01:03:39.009,01:03:48.910
Само бих добавила, че това е пример за заместители (proxies), защото тук се използва арест

01:03:48.910,01:03:56.210
като заместител (proxy) за престъпление и мисля, че почти във всички случаи, данните, които имате

01:03:56.210,01:04:00.049
са заместител на някаква стойност, която реално ви интересува

01:04:00.049,01:04:06.109
И разликата между заместителя и действителната стойност често може да се окаже значителна.

01:04:06.109,01:04:10.770
Благодаря, Рейчъл.

01:04:10.770,01:04:13.430
Това е наистина важен момент.

01:04:13.430,01:04:24.219
Добре, нека приключим, като разгледаме, какво става в този програмен код.

01:04:24.219,01:04:34.880
Кодът, който изпълняваме, е ... един, два, три, четри, пет, шест ... реда код.

01:04:34.880,01:04:39.829
Първият ред е ред за импортиране (import)

01:04:39.829,01:04:46.690
В Python не може да използвате външна библиотека, докато не импортирате от нея

01:04:46.690,01:04:53.339
Обикновено в Python, хората импортират само тези функции и класове, които им трябват

01:04:53.339,01:04:55.030
от библиотеката

01:04:55.030,01:05:01.989
Но Python предлага и удобен начин, с който може да импортирате всичко от един модул, 

01:05:01.989,01:05:04.410
който е да се постави *

01:05:04.410,01:05:07.029
В повечето случаи това е лоша идея

01:05:07.029,01:05:12.479
защото, по подразбиране, начинът, по който работи Python е, че ако въведете import *, той не 

01:05:12.479,01:05:16.640
въвежда само нещата, които са интересни и важни от библиотеката, 

01:05:16.640,01:05:18.520
от която опитвате да вземете нещо

01:05:18.520,01:05:23.369
но въвежда и неща от всички библиотеки, които тази библиотека използва, и от всички библиотеки, които те използат

01:05:23.369,01:05:27.190
и накрая приключвате взривявайки пространството на имената по ужасни начини и предизвиквайки най-различни

01:05:27.190,01:05:28.760
дефекти (бъгове).

01:05:28.760,01:05:36.510
Понеже fastai е проектирана да се използва в тази PERL среда, където искате да има възможност

01:05:36.510,01:05:41.779
да правите голямо количество бързо прототипиране, ние изразходихме много време за да измислим,

01:05:41.779,01:05:45.410
как да избегнем този проблем, така че да може да импортирате със звезда безопасно.

01:05:45.410,01:05:49.630
Дали ще правите така или не, зависи изцяло от вас

01:05:49.630,01:05:56.609
Но това е гарантирано, че ако импортирате * от библиотека на fastai, тя е изрично

01:05:56.609,01:06:01.999
проектирана по начин, че да получите само тези части, които в действителност ви трябват

01:06:01.999,01:06:05.799
Едно нещо, което трябва да се спомене, е във видеото, което виждате, тя се нарича "fastai2"

01:06:05.799,01:06:09.849
Това е така, защото записваме този видеоклип, използвайки предварителна версия.

01:06:09.849,01:06:19.049
До момента, в който гледате онлайн (MOOC) версията, двойката ще е изчезнала.

01:06:19.049,01:06:25.609
Друго за отбелязване е, че в момента, в който говоря, има четири основни предварително дефинирани приложения

01:06:25.609,01:06:31.099
във fastai - изображения (vision, компютърно зрение), текст (text), таблични (tabular) и съвместно филтриране (collaborative filtering)

01:06:31.099,01:06:35.130
Ще научим за всички тях и много повече.

01:06:35.130,01:06:41.989
За всяко едно, да кажем vision, може да импортирате от .all, един вид мета-модул,

01:06:41.989,01:06:42.989
предполагам така може да го наречем

01:06:42.989,01:06:48.079
И това ще ви даде всички неща, от които се нуждаете за най-типичните приложения с изображения.

01:06:48.079,01:06:55.779
И така, ако използвате система REPL като Jupyter notebook, това ще ви предостави всички неща,

01:06:55.779,01:07:01.619
от които се нуждаете, без да се налага да се връщате назад и да го мислите.

01:07:01.619,01:07:06.559
Един от проблемите с това е, че много потребители на Python не ...

01:07:06.559,01:07:12.450
Ако погледнат към нещо, като untar_data, те ще разберат от къде идва

01:07:12.450,01:07:14.219
като погледнат на реда с import-ите

01:07:14.219,01:07:15.970
Ако импортирате звезда, не може да правите повече така.

01:07:15.970,01:07:19.829
Добрата новина е, че в REPL това не ви е нужно

01:07:19.829,01:07:27.450
Можете буквално да въведете символ, да натиснете SHIFT - ENTER и ще ви каже точно

01:07:27.450,01:07:28.670
от къде е дошъл.

01:07:28.670,01:07:29.940
Както виждате

01:07:29.940,01:07:33.510
И това е много удобно.

01:07:33.510,01:07:43.859
В този случай, например, за да направим изграждането на набора с данни, извикахме ImageDataLoaders.from_name_func.

01:07:43.859,01:07:51.170
Всъщност, мога да извикам специалната функция doc за да получа документацията

01:07:51.170,01:07:57.349
и както виждате, тя ми казва точно всичко, което трябва да подам, какви са стойностите по подразбиране, и

01:07:57.349,01:08:07.940
най-важност, не само какво прави, но "show in docs" ме прехвърля към пълната документация,

01:08:07.940,01:08:11.190
включваща и пример.

01:08:11.190,01:08:17.180
Всичко в документацията на fastai има пример и готиното е, че 

01:08:17.180,01:08:20.770
цялата документация е написана в Jupyter тетрадки.

01:08:20.770,01:08:25.540
Това означава, че можете да отворите тетрадката Jupyter за този документ и сами да изпълните

01:08:25.540,01:08:33.280
съответния ред програмен код, да го видите в работа и да разгледате резултатите, и т.н.

01:08:33.280,01:08:36.760
Също така в документацията ще откриете, че има куп уроци

01:08:36.760,01:08:40.501
Например, ако погледнете урока за vision, той ще покрива много неща, но едно

01:08:40.501,01:08:44.910
от нещата е, както виждате в случая, почти същия вид неща,

01:08:44.910,01:08:47.710
каквито гледаме в урок 1.

01:08:47.710,01:08:54.300
Така че във fastAI има много документация и да се възползвате от нея е доста добра идея

01:08:54.300,01:08:59.310
Тя е напълно достъпна за търсене и както споменах, може би най-важното, всяка една от тези 

01:08:59.310,01:09:05.050
страници документация е също и напълно интерактивна Jupyter тетрадка.

01:09:05.050,01:09:13.839
и така, разглеждайки ще от кода, първият ред след импортирането е нещо, което

01:09:13.839,01:09:14.910
използва untar_data.

01:09:14.910,01:09:20.020
Това ще свали набора с данни, ще го разкомперсира и ще го сложи на компютъра ви.

01:09:20.020,01:09:22.770
Ако вече е свален, няма да го свали повторно.

01:09:22.770,01:09:25.710
Ако е вече декомпресиран, няма да го декомпресира отново.

01:09:25.710,01:09:32.540
И както виждате, fastai има предварително зададен достъп до редица много полезни набори с данни,

01:09:32.540,01:09:34.180
като този набор PETS с домашни любимци

01:09:34.180,01:09:39.920
Данните са изключително важна част от Deep Learning, както може да си представите

01:09:39.920,01:09:41.900
Ще виждаме много такива.

01:09:41.900,01:09:47.690
Създадени са от много герои, които са прекарали месеци или години

01:09:47.690,01:09:51.260
събирайки данни, които можем да използваме за да създаваме модели.

01:09:51.260,01:10:01.230
Следващата стъпка е да кажем на fastai, какви са тези данни и това ще го изучаваме подробно  

01:10:01.230,01:10:05.560
Но в случая ние основно казваме:
„Добре, съдържа изображения“ (Image...).

01:10:05.560,01:10:07.630
Съдържа изображения, които са на този път (path)

01:10:07.630,01:10:14.100
untar_data връща пътят, т.е. къде е бил декомпресиран наборът с данни

01:10:14.100,01:10:18.900
или ако е вече декомпресиран, ни казва къде е бил декомпресиран преди.

01:10:18.900,01:10:23.560
Трябва да и кажем неща като, какви изображения са на този път.

01:10:23.560,01:10:27.170
Едно от интересните неща е label_func

01:10:27.170,01:10:33.600
Как да кажете за всеки файл дали е котка или куче?

01:10:33.600,01:10:37.330
И ако погледнете във файлът със сведения (ReadMe) на оригиналният набор с данни, там се използва леко чудат

01:10:37.330,01:10:42.430
подход, който е, казват "о, всичко, където първата буква на името на файла е 

01:10:42.430,01:10:45.000
главна буква е котка".

01:10:45.000,01:10:46.430
Така са решили.

01:10:46.430,01:10:51.180
Затова тук просто създадохме малка функция, наречена is_cat, която връща първата буква,

01:10:51.180,01:10:52.480
дали е главна или не.

01:10:52.480,01:10:57.420
И казваме на fastai "така разбираш, дали е котка".

01:10:57.420,01:11:01.260
Ще се върнем към тези две след малко.

01:11:01.260,01:11:04.640
И така, следващото нещо, дотук разказахме какви са данните.

01:11:04.640,01:11:06.350
След това трябва да създадем нещо, наречено learner (изучаващ)

01:11:06.350,01:11:10.180
learner е нещо, което се учи, то прави обучението (training)

01:11:10.180,01:11:12.510
Трябва да му кажете, какви данни да ползва

01:11:12.510,01:11:16.570
След това, трябва да му кажете, каква архитектура да ползва.

01:11:16.570,01:11:19.810
Ще говоря много за това през курса.

01:11:19.810,01:11:25.460
Но в общи линии, съществуват много предварително зададени архитектури на невронни мрежи, които имат определени

01:11:25.460,01:11:26.660
предимства и недостатъци.

01:11:26.660,01:11:30.360
И за компютърното зрение (computer vision), архитектурата се нарича ResNet.

01:11:30.360,01:11:34.580
Просто много добра отправна точка, и ние просто ще използваме една 

01:11:34.580,01:11:35.820
сравнително малка.

01:11:35.820,01:11:39.710
Така че всичко това е предварително дефинирано и настроено за вас.

01:11:39.710,01:11:43.380
И след това можете да кажете на fastai, какви неща искате да се разпечатват, докато протича обучение.

01:11:43.380,01:11:47.730


01:11:47.730,01:11:51.230


01:11:51.230,01:11:57.050


01:11:57.050,01:12:00.700


01:12:00.700,01:12:08.160


01:12:08.160,01:12:09.230


01:12:09.230,01:12:12.730


01:12:12.730,01:12:19.890


01:12:19.890,01:12:22.290


01:12:22.290,01:12:27.040


01:12:27.040,01:12:31.220


01:12:31.220,01:12:33.540


01:12:33.540,01:12:35.090


01:12:35.090,01:12:38.860


01:12:38.860,01:12:44.050


01:12:44.050,01:12:47.940


01:12:47.940,01:12:50.970


01:12:50.970,01:12:53.240


01:12:53.240,01:13:00.010


01:13:00.010,01:13:01.640


01:13:01.640,01:13:06.060


01:13:06.060,01:13:08.570


01:13:08.570,01:13:11.970


01:13:11.970,01:13:14.510


01:13:14.510,01:13:22.370


01:13:22.370,01:13:23.370


01:13:23.370,01:13:27.480


01:13:27.480,01:13:31.620


01:13:31.620,01:13:36.830


01:13:36.830,01:13:41.270


01:13:41.270,01:13:49.230


01:13:49.230,01:13:51.100


01:13:51.100,01:13:57.080


01:13:57.080,01:14:04.500


01:14:04.500,01:14:11.000


01:14:11.000,01:14:18.060


01:14:18.060,01:14:22.960


01:14:22.960,01:14:27.120


01:14:27.120,01:14:34.700


01:14:34.700,01:14:39.260


01:14:39.260,01:14:44.100


01:14:44.100,01:14:49.350


01:14:49.350,01:14:53.410


01:14:53.410,01:14:59.250


01:14:59.250,01:15:05.890


01:15:05.890,01:15:07.130


01:15:07.130,01:15:11.240


01:15:11.240,01:15:19.940


01:15:19.940,01:15:23.940


01:15:23.940,01:15:31.230


01:15:31.230,01:15:34.000


01:15:34.000,01:15:40.750


01:15:40.750,01:15:45.600


01:15:45.600,01:15:52.440


01:15:52.440,01:15:56.420


01:15:56.420,01:16:00.910


01:16:00.910,01:16:05.270


01:16:05.270,01:16:08.480


01:16:08.480,01:16:17.001


01:16:17.001,01:16:27.580


01:16:27.580,01:16:33.740


01:16:33.740,01:16:39.070


01:16:39.070,01:16:42.520


01:16:42.520,01:16:45.420


01:16:45.420,01:16:51.850


01:16:51.850,01:16:54.201


01:16:54.201,01:16:59.410


01:16:59.410,01:17:02.960


01:17:02.960,01:17:06.520


01:17:06.520,01:17:08.480


01:17:08.480,01:17:13.060


01:17:13.060,01:17:15.710


01:17:15.710,01:17:21.400


01:17:21.400,01:17:26.300


01:17:26.300,01:17:31.890


01:17:31.890,01:17:34.950


01:17:34.950,01:17:36.980


01:17:36.980,01:17:39.520


01:17:39.520,01:17:42.530


01:17:42.530,01:17:43.830


01:17:43.830,01:17:49.250


01:17:49.250,01:17:55.380


01:17:55.380,01:18:04.440


01:18:04.440,01:18:08.960


01:18:08.960,01:18:13.500


01:18:13.500,01:18:19.960


01:18:19.960,01:18:21.670


01:18:21.670,01:18:31.700


01:18:31.700,01:18:33.390


01:18:33.390,01:18:35.110


01:18:35.110,01:18:38.270


01:18:38.270,01:18:39.970


01:18:39.970,01:18:52.030


01:18:52.030,01:18:53.030


01:18:53.030,01:18:56.620


01:18:56.620,01:18:57.620


01:18:57.620,01:18:59.600


01:18:59.600,01:19:02.700


01:19:02.700,01:19:10.850


01:19:10.850,01:19:17.430


01:19:17.430,01:19:18.880


01:19:18.880,01:19:23.230


01:19:23.230,01:19:29.520


01:19:29.520,01:19:34.420


01:19:34.420,01:19:41.700


01:19:41.700,01:19:43.980


01:19:43.980,01:19:47.180


01:19:47.180,01:19:56.840


01:19:56.840,01:20:01.630


01:20:01.630,01:20:09.850


01:20:09.850,01:20:14.350


01:20:14.350,01:20:18.250


01:20:18.250,01:20:23.221


01:20:23.221,01:20:29.850


01:20:29.850,01:20:32.710


01:20:32.710,01:20:36.520


01:20:36.520,01:20:39.500


01:20:39.500,01:20:45.730


01:20:45.730,01:20:53.780


01:20:53.780,01:20:58.470


01:20:58.470,01:21:06.010


01:21:06.010,01:21:14.750


01:21:14.750,01:21:20.480


01:21:20.480,01:21:22.270


01:21:22.270,01:21:26.090


01:21:26.090,01:21:30.340


01:21:30.340,01:21:34.710


01:21:34.710,01:21:41.360


01:21:41.360,01:21:47.850


01:21:47.850,01:21:52.980


01:21:52.980,01:21:58.360


01:21:58.360,01:22:01.020


01:22:01.020,01:22:04.130


01:22:04.130,01:22:08.350


01:22:08.350,01:22:14.880


01:22:14.880,01:22:22.150


01:22:22.150,01:22:27.500


01:22:27.500,01:22:29.960


01:22:29.960,01:22:30.440


